{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data for Case studies\n",
    "\n",
    "we will generate all the necessary data for the paper in this workbook\n",
    "This means:\n",
    "- 3 case studies, each with their respective test and reference sessions\n",
    "- 2D matching: \n",
    "  - show examples of good and bad matches with the inlier lines and the resulting projection errors\n",
    "  - show the results of each method separately and weighted average over all the test images, this results\n",
    "    - each test returns one estimated pose per test image and or mesh (each time there is a search for the best match)\n",
    "  - compare the estimated global pose against the actual one\n",
    "- 3D matching:\n",
    "  - show example of good and bad matches\n",
    "  - show the correspondences in 3D space with the inlier percent and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the relevant modules\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import session\n",
    "from imagematch import ImageMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Selection:\n",
    "Pick one of the 3 cases underneath to apply all the functions to the relevant case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 0: Kamer\n",
    "Bedroom for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalPos = np.array([0,0,0])\n",
    "accuraccy = 10\n",
    "\n",
    "testSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/TestSessions/0_Kamer\"\n",
    "resultPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/Results/0_Kamer\"\n",
    "# Getting the test session from the device/path\n",
    "testSession = session.Session().from_path(testSessionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: Campus\n",
    "The technologiecampus Gent, with the focus on the 3 different rooms that were tested: Dubo, Beton, grond\n",
    "The main test here is locating withing a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalPos = np.array([0,0,0])\n",
    "accuraccy = 10\n",
    "\n",
    "testSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/TestSessions/1_Campus\"\n",
    "resultPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/Results/1_Campus\"\n",
    "# Getting the test session from the device/path\n",
    "testSession = session.Session().from_path(testSessionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: House\n",
    "The house of Maarten Bassier which has had a renovation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalPos = np.array([0,0,0])\n",
    "accuraccy = 10\n",
    "\n",
    "testSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/TestSessions/2_House\"\n",
    "resultPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/Results/2_House\"\n",
    "# Getting the test session from the device/path\n",
    "testSession = session.Session().from_path(testSessionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: LivingLab\n",
    "The living lab house which has been recorded over all the phases of the building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalPos = np.array([0,0,0])\n",
    "accuraccy = 10\n",
    "\n",
    "testSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/TestSessions/1_Campus\"\n",
    "resultPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/Results/1_Campus\"\n",
    "# Getting the test session from the device/path\n",
    "testSession = session.Session().from_path(testSessionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple reference sessions:\n",
    "With the given global position, only the relevant sessions are stored and parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the Reference folder with all the reference sesisons\n",
    "refSessionsPath = \"/Volumes/Data drive/Documents/Doctoraat Local/XR Paper Data/RefSessions\"\n",
    "refSessions = session.find_close_sessions(refSessionsPath, globalPos, accuraccy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Session selection\n",
    "This also has an option to select one single session to compare against\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Getting the test session from the device/path\n",
    "testSession = session.Session().from_path(testSessionPath)\n",
    "#test with 1 reference session\n",
    "refSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/PythonDataAlignment/src/positioning/images/session-2022-01-14 09-23-42\"\n",
    "refSessions = [session.Session().from_path(refSessionPath)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing all the matches\n",
    "\n",
    "this prints out all the match results with all the reference images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagematch import ImageMatch\n",
    "\n",
    "results = []\n",
    "\n",
    "#test every test image against every reference image and get the match object to check the error and confidence\n",
    "for refSession in refSessions:\n",
    "    print(\"Matching reference session:\", refSession.sessionId)\n",
    "\n",
    "    for testImage in testSession.imageTransforms:\n",
    "        print(\"Test Image:\", testImage.id, \"has a matchError of:\")\n",
    "        for refImage in refSession.imageTransforms:\n",
    "            newMatch = ImageMatch(refImage, testImage)\n",
    "            newMatch.find_matches() # find the best matches \n",
    "            results.append(newMatch)\n",
    "            print(newMatch.matchError, \"With image:\", refImage.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good and bad match examples\n",
    "This prints out a very good and very bad match based on the match score, also shows the correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand pick the good and bad matches\n",
    "testImage = testSession.imageTransforms[1]\n",
    "goodImage = testSession.imageTransforms[2]\n",
    "badImage = testSession.imageTransforms[6]\n",
    "\n",
    "bestMatch = ImageMatch(testImage, goodImage)\n",
    "worstMatch = ImageMatch(testImage, badImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best and worst match in the list of all the images\n",
    "\n",
    "imageNr = len(testSession.imageTransforms)\n",
    "\n",
    "bestMatch: ImageMatch = None\n",
    "worstMatch: ImageMatch = None\n",
    "\n",
    "for i in range(0,imageNr):\n",
    "    for j in range(i+1, imageNr):\n",
    "        print(i, \" vs. \", j)\n",
    "        newMatch = ImageMatch(testSession.imageTransforms[i], testSession.imageTransforms[j])\n",
    "        newMatch.find_matches() # find the best matches\n",
    "        if(bestMatch == None or bestMatch.matchError > newMatch.matchError):\n",
    "            bestMatch = newMatch\n",
    "        if(worstMatch == None or worstMatch.matchError < newMatch.matchError):\n",
    "            worstMatch = newMatch\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestMatch.get_essential_matrix()\n",
    "goodmatches = bestMatch.draw_image_matches()\n",
    "goodinliers = bestMatch.draw_image_inliers()\n",
    "\n",
    "worstMatch.get_essential_matrix()\n",
    "badmatches = worstMatch.draw_image_matches()\n",
    "badinliers = worstMatch.draw_image_inliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagematch import ImageMatch\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def show_and_save_matches(title, image, error):\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    plt.axis('off')\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title + \"\\n Error:\" + str(error))\n",
    "    plt.savefig(os.path.join(resultPath,\"match examples\", title))\n",
    "    plt.show()\n",
    "\n",
    "show_and_save_matches('Bad Image Match', badmatches, worstMatch.matchError)\n",
    "show_and_save_matches('Bad Image Inliers', badinliers, worstMatch.matchError)\n",
    "show_and_save_matches('Good Image Match', goodmatches, bestMatch.matchError)\n",
    "show_and_save_matches('Good Image Inliers', goodinliers, bestMatch.matchError)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose estimations method 1 (cross reference matching)\n",
    "Using 2 separate matches to calculate the final pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import positioning2d as pos2d\n",
    "\n",
    "for refsession in refSessions:\n",
    "\n",
    "    for testImage in testSession.imageTransforms:\n",
    "        print(\"Test Image:\", testImage.id)\n",
    "        R,t, confidence = pos2d.cross_reference_matching(testImage, refSession)\n",
    "\n",
    "        testOriginRot = testImage.get_rotation_matrix().T @ R\n",
    "        testOrgininPos = - testOriginRot @ t\n",
    "        testSession.add_pose_guess(refSession, testOriginRot, testOrgininPos, confidence)\n",
    "        print(\"Estimated pose wit confidence:\", confidence)\n",
    "        print(\"R: \\n\", testOriginRot, \"\\n t:\\n\", testOrgininPos.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose estimation method 2 (incremental)\n",
    "using 2 connected matches to find an estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will test every test image against all the reference images and their best match\n",
    "\n",
    "import positioning2d as pos2d\n",
    "\n",
    "for refsession in refSessions:\n",
    "\n",
    "    for testImage in testSession.imageTransforms:\n",
    "        print(\"Test Image:\", testImage.id, \"matched with:\")\n",
    "        R,t, confidence = pos2d.incremental_matching(testImage, refSession)\n",
    "\n",
    "        testOriginRot = testImage.get_rotation_matrix().T @ R\n",
    "        testOrgininPos = - testOriginRot @ t\n",
    "        testSession.add_pose_guess(refSession, testOriginRot, testOrgininPos, confidence)\n",
    "        print(\"Estimated pose wit confidence:\", confidence)\n",
    "        print(\"R: \\n\", testOriginRot, \"\\n t:\\n\", testOrgininPos.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose estimation method 3 (raycasting)\n",
    "using the 3D scene to get the session scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will test every test image against all the reference images and their best match\n",
    "\n",
    "import positioning2d as pos2d\n",
    "\n",
    "for refsession in refSessions:\n",
    "\n",
    "    for testImage in testSession.imageTransforms:\n",
    "        print(\"Test Image:\", testImage.id, \"matched with:\")\n",
    "        R,t, confidence = pos2d.raycast_matching(testImage, refSession) #get the rotation and translation with the pnp point algorithm\n",
    "\n",
    "        testOriginRot = testImage.get_rotation_matrix().T @ R\n",
    "        testOrgininPos = - testOriginRot @ t\n",
    "        testSession.add_pose_guess(refSession, testOriginRot, testOrgininPos, confidence)\n",
    "        print(\"Estimated pose wit confidence:\", confidence)\n",
    "        print(\"R: \\n\", testOriginRot, \"\\n t:\\n\", testOrgininPos.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D alignment\n",
    "\n",
    "This section covers the 3D alignment process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good and bad matches examples\n",
    "\n",
    "shows good and bad matches based on the error and inlier percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying corespondances\n",
    "import open3d as o3d\n",
    "import positioning3d as pos3d\n",
    "from geometrymatch import GeometryMatch\n",
    "from geometrytransform import GeometryTransform\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pcd1Path = \"/Users/jellevermandere/Downloads/Users/travis/build/nmellado/Super4PCS/Super4PCS-v1.1.3-osx-clang++/assets/roomPart.obj\"\n",
    "pcd2Path = \"/Users/jellevermandere/Downloads/Users/travis/build/nmellado/Super4PCS/Super4PCS-v1.1.3-osx-clang++/assets/roomHolo.obj\"\n",
    "pcd3Path = \"/Volumes/Data drive/Documents/Doctoraat Local/PythonDataAlignment/src/positioning/images/session-2022-01-14 09-23-42/mesh-2022-01-14 09-23-42.obj\"\n",
    "\n",
    "testPcd = GeometryTransform().from_path(pcd1Path)\n",
    "goodPcd = GeometryTransform().from_path(pcd2Path)\n",
    "badPcd = GeometryTransform().from_path(pcd3Path)\n",
    "\n",
    "goodmatch = GeometryMatch(testPcd, goodPcd, 0.05)\n",
    "goodresult = goodmatch.get_transformation()\n",
    "goodlineset = goodmatch.draw_matches()\n",
    "print(\"goodRMSE:\",goodresult.inlier_rmse)\n",
    "print(\"goodFitness:\",goodresult.fitness)\n",
    "badmatch = GeometryMatch(testPcd, badPcd, 0.05)\n",
    "badresult = badmatch.get_transformation()\n",
    "badlineset = badmatch.draw_matches()\n",
    "print(\"badRMSE:\",badresult.inlier_rmse)\n",
    "print(\"badFitness:\",badresult.fitness)\n",
    "\n",
    "#pos3d.show_geometries([testPcd.get_voxel_pcd(),  goodPcd.get_voxel_pcd(),badPcd.get_voxel_pcd(), goodlineset, badlineset], True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodmovedPcd = copy.deepcopy(goodPcd.geometry)\n",
    "goodmovedPcd.transform(goodresult.transformation)\n",
    "goodmovedPcd.compute_vertex_normals()\n",
    "\n",
    "pos3d.show_geometries([testPcd.get_voxel_pcd(), goodmovedPcd,goodPcd.get_voxel_pcd(), goodlineset], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badmovedPcd = copy.deepcopy(badPcd.geometry)\n",
    "badmovedPcd.transform(badresult.transformation)\n",
    "badmovedPcd.compute_vertex_normals()\n",
    "\n",
    "pos3d.show_geometries([testPcd.get_voxel_pcd(), badmovedPcd,badPcd.get_voxel_pcd(), badlineset], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: FPFH feature matching\n",
    "\n",
    "the first method involves matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import session\n",
    "import positioning3d as pos3d\n",
    "\n",
    "# Getting the test session from the device/path\n",
    "#testSessionPath = \"/Volumes/GeomaticsProjects1/Projects/2025-03 Project FWO SB Jelle/7.Data/21-11 Testbuilding Campus/RAW Data/Hololens/session-2021-11-25 16-09-47\"\n",
    "testSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/PythonDataAlignment/src/positioning/images/session-2022-01-14 09-23-42\"\n",
    "testSession = session.Session().from_path(testSessionPath)\n",
    "#test with 1 reference session\n",
    "refSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/PythonDataAlignment/src/positioning/images/session-2022-01-14 09-23-42\"\n",
    "refSession = session.Session().from_path(refSessionPath)\n",
    "\n",
    "pos3d.compare_session(testSession, refSession, 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the Estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import positioning3d as pos3d\n",
    "import open3d as o3d\n",
    "# show all the estimations in 3d space from black to white, by confidence\n",
    "\n",
    "points = []\n",
    "colors = []\n",
    "\n",
    "for estimation in testSession.estimations:\n",
    "    points.append(estimation[1])\n",
    "    colors.append(estimation[2] * [1,1,1])\n",
    "\n",
    "estimatedPoints = o3d.geometry.PointCloud()\n",
    "estimatedPoints.points = o3d.utility.Vector3dVector(points)\n",
    "estimatedPoints.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "pos3d.show_geometries([estimatedPoints])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "277d597ac5262525bb972cf35caa42eec0dd0b1ee2f46a31453e7fe567547464"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
