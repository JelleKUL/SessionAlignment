{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data for Case studies\n",
    "\n",
    "we will generate all the necessary data for the paper in this workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Define global Coordinates\n",
    "globalPos = np.array([0,0,0])\n",
    "accuraccy = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positioning import session\n",
    "\n",
    "# Locating the Reference folder with all the reference sesisons\n",
    "refSessionsPath = \"/Volumes/GeomaticsProjects1/Projects/2025-03 Project FWO SB Jelle/7.Data/21-11 Testbuilding Campus/RAW Data\"\n",
    "refSessions = session.find_close_sessions(refSessionsPath, globalPos, accuraccy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positioning import session\n",
    "\n",
    "# Getting the test session from the device/path\n",
    "#testSessionPath = \"/Volumes/GeomaticsProjects1/Projects/2025-03 Project FWO SB Jelle/7.Data/21-11 Testbuilding Campus/RAW Data/Hololens/session-2021-11-25 16-09-47\"\n",
    "testSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/PythonDataAlignment/src/positioning/images/session-2021-11-25 11-12-17\"\n",
    "testSession = session.Session().from_path(testSessionPath)\n",
    "#test with 1 reference session\n",
    "refSessionPath = \"/Volumes/Data drive/Documents/Doctoraat Local/PythonDataAlignment/src/positioning/images/session-2022-01-14 09-23-42\"\n",
    "refSession = session.Session().from_path(refSessionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing all the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positioning.imagematch import ImageMatch\n",
    "\n",
    "results = []\n",
    "\n",
    "#test every test image against every reference image and get the match object to check the error and confidence\n",
    "for refSession in refSessions:\n",
    "    print(\"Matching reference session:\", refSession.sessionId)\n",
    "\n",
    "    for testImage in testSession.imageTransforms:\n",
    "        print(\"Test Image:\", testImage.id, \"has a matchError of:\")\n",
    "        for refImage in refSession.imageTransforms:\n",
    "            newMatch = ImageMatch(refImage, testImage)\n",
    "            newMatch.find_matches() # find the best matches \n",
    "            results.append(newMatch)\n",
    "            print(newMatch.matchError, \"With image:\", refImage.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pose estimations method 1 (cross reference matching)\n",
    "Using 2 separate matches to calculate the final pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import positioning.positioning2d as pos2d\n",
    "from positioning.imagematch import ImageMatch\n",
    "\n",
    "for testImage in testSession.imageTransforms:\n",
    "    print(\"Test Image:\", testImage.id, \"matched with:\")\n",
    "    for refImage1 in refSession.imageTransforms:\n",
    "        match1 = ImageMatch(refImage1, testImage)\n",
    "        match1.find_matches()\n",
    "        match1.get_essential_matrix()\n",
    "        print(\"image1:\", refImage1.id, \"Error:\", match1.matchError)\n",
    "        for refImage2 in refSession.imageTransforms:\n",
    "            if(refImage1.id == refImage2.id): continue # skip the same images\n",
    "            match2 = ImageMatch(refImage2, testImage)\n",
    "            match2.find_matches()\n",
    "            match2.get_essential_matrix()\n",
    "            print(\"image2:\", refImage2.id, \"Error:\", match2.matchError)\n",
    "            R,t, confidence = pos2d.cross_reference_pose(match1, match2)\n",
    "\n",
    "            testOriginRot = testImage.get_rotation_matrix().T @ R\n",
    "            testOrgininPos = - testOriginRot @ t\n",
    "            testSession.add_pose_guess(refSession, testOriginRot, testOrgininPos, confidence)\n",
    "            print(\"Estimated pose wit confidence:\", confidence)\n",
    "            print(\"R: \\n\", testOriginRot, \"\\n t:\\n\", testOrgininPos.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pose estimation method 2 (incremental)\n",
    "using 2 connected matches to find an estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will test every test image against all the reference images and their best match\n",
    "\n",
    "import positioning.positioning2d as pos2d\n",
    "from positioning.imagematch import ImageMatch\n",
    "\n",
    "for testImage in testSession.imageTransforms:\n",
    "    print(\"Test Image:\", testImage.id, \"matched with:\")\n",
    "    for refImage in refSession.imageTransforms:\n",
    "        testMatch = ImageMatch(testImage, refImage)\n",
    "        refMatch = pos2d.get_best_session_match(refImage, refSession)\n",
    "\n",
    "        R,t = testMatch.get_pnp_pose(refMatch) #get the rotation and translation with the pnp point algorithm\n",
    "        confidence = testMatch.fidelity * refMatch.fidelity\n",
    "\n",
    "        testOriginRot = testImage.get_rotation_matrix().T @ R\n",
    "        testOrgininPos = - testOriginRot @ t\n",
    "        testSession.add_pose_guess(refSession, testOriginRot, testOrgininPos, confidence)\n",
    "        print(\"Estimated pose wit confidence:\", confidence)\n",
    "        print(\"R: \\n\", testOriginRot, \"\\n t:\\n\", testOrgininPos.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pose estimation method 3 (raycasting)\n",
    "using the 3D scene to get the session scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will test every test image against all the reference images and their best match\n",
    "\n",
    "import positioning.positioning2d as pos2d\n",
    "from positioning.imagematch import ImageMatch\n",
    "\n",
    "for testImage in testSession.imageTransforms:\n",
    "    print(\"Test Image:\", testImage.id, \"matched with:\")\n",
    "    for refImage in refSession.imageTransforms:\n",
    "        match = ImageMatch(testImage, refImage)\n",
    "        match.find_matches()\n",
    "        match.get_essential_matrix()\n",
    "        match.triangulate(useCameraPose = True)\n",
    "\n",
    "        if(len(testSession.geometries) > 0):\n",
    "            # the test sesison has geometry\n",
    "            geometry = testSession.geometries[0]\n",
    "            camera = testImage\n",
    "        \n",
    "        if(len(refSession.geometries) > 0):\n",
    "            # the ref sesison has geometry\n",
    "            geometry = refSession.geometries[0]\n",
    "            camera = refImage\n",
    "\n",
    "        geometry.get_distance_from_point(camera.pos, camera.rot)\n",
    "\n",
    "        R,t = testMatch.get_pnp_pose(refMatch) #get the rotation and translation with the pnp point algorithm\n",
    "        confidence = testMatch.fidelity * refMatch.fidelity\n",
    "\n",
    "        testOriginRot = testImage.get_rotation_matrix().T @ R\n",
    "        testOrgininPos = - testOriginRot @ t\n",
    "        testSession.add_pose_guess(refSession, testOriginRot, testOrgininPos, confidence)\n",
    "        print(\"Estimated pose wit confidence:\", confidence)\n",
    "        print(\"R: \\n\", testOriginRot, \"\\n t:\\n\", testOrgininPos.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the Estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import positioning.positioning3d as pos3d\n",
    "import open3d as o3d\n",
    "# show all the estimations in 3d space from black to white, by confidence\n",
    "\n",
    "points = []\n",
    "colors = []\n",
    "\n",
    "for estimation in testSession.estimations:\n",
    "    points.append(estimation[1])\n",
    "    colors.append(estimation[2] * [1,1,1])\n",
    "\n",
    "estimatedPoints = o3d.geometry.PointCloud()\n",
    "estimatedPoints.points = o3d.utility.Vector3dVector(points)\n",
    "estimatedPoints.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "pos3d.show_geometries([estimatedPoints])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "277d597ac5262525bb972cf35caa42eec0dd0b1ee2f46a31453e7fe567547464"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
